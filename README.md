# Implementation of Algorithms Covered in Foundations of Reinforcement Learning

This repository contains implementations of some of the algorithms covered in [MIT 6.7920: Reinforcement Learning: Foundations And Methods](https://web.mit.edu/6.7920/www/index.html) in Python.

The directory `src` contains Python code which can be run directly.
The algorithms that require training neural networks use [JAX](https://github.com/google/jax) and are compatible with GPUs that support CUDA.

## Algorithms Covered:

- Value Iteration
- Linear Quadratic Resolver (LQR)
- Policy Iteration
- Temporal Difference Learning
- TD(Î»)
- SARSA
- Q-Learning
- Linear Temporal Difference Learning (Linear TD)
- Least Squares Temporal Difference Learning (LSTD)
- Deep Q-Networks (DQN) and Double DQN (DDQN)
- REINFORCE
- Actor-Critic
- Actor Critic with Advantage (A2C)
- Conservative Policy Iteration
- Trust Region Policy Optimization (TRPO)
- Proximal Policy Optimization (PPO)
- Monte Carlo Tree Search
- MuZero

## License

This code is currently under the Apache 2.0 license and is for educational purposes only.
This code is neither intended nor designed for commercial use.
